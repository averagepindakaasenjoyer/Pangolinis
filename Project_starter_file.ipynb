{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac9089c",
   "metadata": {},
   "source": [
    "Uploaded for the sake of uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7b671b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "file_path = os.getenv('FILE_PATH')\n",
    "\n",
    "filenames = [\n",
    "    'bag_ids_no_funda',\n",
    "    'random_online_sample',\n",
    "    'special_house_types_class_sample',\n",
    "    'detailed_woning_type_sample',\n",
    "    'not_online_listings', # Download from slack\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9bb469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Samsung_USB/\n"
     ]
    }
   ],
   "source": [
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3082f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    filename = filename + '.parquet' if not filename.endswith('.parquet') else filename\t\n",
    "    df = pd.read_parquet(file_path + filename, engine='pyarrow')\n",
    "    df.to_csv(\n",
    "        file_path + filename.replace('.parquet', '.csv'),\n",
    "        index=False,\n",
    "        encoding='utf-8',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3c7261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bag_ids_no_funda', 'random_online_sample', 'special_house_types_class_sample', 'detailed_woning_type_sample', 'not_online_listings']\n"
     ]
    }
   ],
   "source": [
    "print(filenames)\n",
    "\n",
    "# When printing the content of the CSV files, the file size becomes too large to be pushed to GitHub.\n",
    "\n",
    "# for filename in filenames:\n",
    "#     filename = filename + '.csv' if not filename.endswith('.csv') else filename\n",
    "#     print(f\"Reading file: {filename}\")\n",
    "#     with open(file_path + filename, 'r', encoding='utf-8') as file:\n",
    "#         content = file.read()\n",
    "#         print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d28986b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path + \"bag_image_summary.csv\")\n",
    "df_sample = pd.read_parquet(file_path + \"detailed_woning_type_sample.parquet\")\n",
    "df = pd.read_csv(file_path + \"bag_image_summary.csv\", dtype=\"string\")\n",
    "df_joined = pd.merge(df_sample, df, how=\"left\", right_on=\"bag_id\", left_on=\"bag_nummeraanduidingid\")\n",
    "df_sample_with_urls = df_joined[df_joined[\"frontview_exists\"].notna()]\n",
    "\n",
    "file_path_with_urls = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "114567fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_path(url, source):\n",
    "    if pd.isna(url):\n",
    "        return ''\n",
    "    id = url.rstrip('/').split('/')[-1]\n",
    "    id, _ = id.split('.')\n",
    "    m = re.match(r'(\\d{2})', id)\n",
    "    first_two_digits = m.group(1) if m else ''\n",
    "    return f\"img_dataset/{first_two_digits}/{id}-{source}.jpg\"\n",
    "\n",
    "cols = ['frontview_funda_url', 'frontview_google_url', 'frontview_funda_in_business_url']\n",
    "sources = ['funda', 'google', 'funda-in-business']\n",
    "\n",
    "for col, source in zip(cols, sources):\n",
    "    df_sample_with_urls[f'{col}_split'] = df_sample_with_urls[col].map(lambda url: extract_path(url, source))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14de7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_path_with_urls == False:\n",
    "    df_sample_with_urls[[f'{col}_split' for col in cols]] = df_sample_with_urls[[f'{col}_split' for col in cols]].map(lambda x: file_path + x if x else '')\n",
    "    file_path_with_urls = True\n",
    "\n",
    "df_sample_with_urls.to_csv(\n",
    "    file_path + \"detailed_woning_type_with_urls.csv\",\n",
    "    index=False,\n",
    "    encoding='utf-8',\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
