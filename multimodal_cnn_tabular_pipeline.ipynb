{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb7eef1",
   "metadata": {},
   "source": [
    "# Multimodal CNN + Tabular Classification Pipeline\n",
    "\n",
    "This notebook defines a modular, extensible pipeline for classifying detailed Dutch housing types based on both **images** (e.g., front view photos from Funda) and **tabular features** (e.g., build year, surface area, monument status).\n",
    "\n",
    "### ðŸ“Œ Notebook Structure\n",
    "\n",
    "1. **Setup**  \n",
    "   Import libraries, define paths, check device (CPU/GPU), and set config options.\n",
    "\n",
    "2. **Data Ingestion**  \n",
    "   Load and merge image metadata with tabular housing data using `bag_id` as key.\n",
    "\n",
    "3. **Preprocessing**  \n",
    "   - Clean and encode label data (woningtype)\n",
    "   - Normalize selected tabular features\n",
    "   - Build image paths\n",
    "   - Filter to valid samples\n",
    "   - Train/validation split\n",
    "\n",
    "4. **Dataset & DataLoader**  \n",
    "   Define a custom PyTorch `Dataset` class to return paired image + tabular tensors, and create `DataLoader`s.\n",
    "\n",
    "5. **Model Definition** *(placeholder)*  \n",
    "   - CNN backbone (e.g., ResNet)\n",
    "   - MLP for tabular features\n",
    "   - Fusion layer and classifier head\n",
    "\n",
    "6. **Training Loop** *(placeholder)*  \n",
    "   Define the training pipeline using F1, accuracy, and recall as evaluation metrics.\n",
    "\n",
    "7. **Evaluation & Export** *(placeholder)*  \n",
    "   - Generate predictions and metrics\n",
    "   - Save trained model and results to disk\n",
    "\n",
    "This structure is modular and can be adjusted as needed. The modeling and training sections will be filled in once data loading and preprocessing are finalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be620149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Section 1: Setup ---\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Find path\n",
    "load_dotenv()\n",
    "BASE_DIR = os.getenv('FILE_PATH')\n",
    "\n",
    "# Paths\n",
    "IMG_DIR = BASE_DIR + '/images'\n",
    "TABULAR_PATH = BASE_DIR + '/detailed_woning_type_sample.csv'\n",
    "IMG_META_PATH = BASE_DIR + '/bag_image_summary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2d9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"CUDA available:\", torch.cuda.is_available())\n",
    "# print(\"CUDA devices:\", torch.cuda.device_count())\n",
    "# print(\"Current device:\", torch.cuda.current_device())\n",
    "# print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72661b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 2: Data Ingestion ---\n",
    "\n",
    "# Koen is ook nog bezig met code, dat kan hier geimplementeerd worden\n",
    "\n",
    "# Load tabular data\n",
    "tabular_df = pd.read_csv(TABULAR_PATH)\n",
    "img_meta = pd.read_csv(IMG_META_PATH)\n",
    "\n",
    "# Normalize column names\n",
    "tabular_df.columns = [col.strip().lower() for col in tabular_df.columns]\n",
    "img_meta.columns = [col.strip().lower() for col in img_meta.columns]\n",
    "\n",
    "# Merge\n",
    "tabular_df = tabular_df.rename(columns={'bag_nummeraanduidingid': 'bag_id'})\n",
    "\n",
    "df = tabular_df.merge(img_meta, on='bag_id', how='left')\n",
    "\n",
    "# Filter: keep only samples with frontview image path\n",
    "df = df[df['frontview_exists'] == True]\n",
    "\n",
    "# TODO\n",
    "# hier moet wat logica over de path files. Komt nadat de paths in 'bag_image_summary' zijn verbeterd.\n",
    "# mogelijk id's droppen die geen foto hebben\n",
    "# nadenken of we die id's ook droppen in onze baseline tabular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da07d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4235 Val size: 1412 Num classes: 15\n"
     ]
    }
   ],
   "source": [
    "# --- Section 3: Data Ingestion ---\n",
    "\n",
    "# TODO\n",
    "# Preprocessing en normalisatie van de data toepassen (koen).\n",
    "\n",
    "# TODO\n",
    "# Training, test en validatie split toevoegen\n",
    "# Zoals dit:\n",
    "# CODE ROSA:\n",
    "\n",
    "test_size_train = 0.4\n",
    "test_size_val = 0.5\n",
    "rnd_state = 42\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=test_size_train, random_state=rnd_state)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=test_size_val, random_state=rnd_state)\n",
    "\n",
    "#optioneel als je er een csv file van wil maar je hebt in principe ny al gwn train_df, val_df en test_df\n",
    "\n",
    "# train_df.to_csv(\"train.csv\", index=False)\n",
    "# val_df.to_csv(\"val.csv\", index=False)\n",
    "# test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"Train size:\", len(train_df), \"Val size:\", len(val_df), \"Num classes:\", df['woningtype'].nunique())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f4889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 4: Dataset and DataLoader ---\n",
    "\n",
    "\n",
    "class HousingDataset(Dataset):\n",
    "    def __init__(self, df, numeric_features, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.numeric_features = numeric_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # We houden het RGB omdat veel modellen uit de packages getrained zijn om RGB\n",
    "        img = Image.open(row['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # Tabular features tensor\n",
    "        tab_feats = torch.tensor(row[self.numeric_features].values, dtype=torch.float32)\n",
    "        \n",
    "        # Label tensor\n",
    "        label = torch.tensor(row['label'], dtype=torch.long)\n",
    "        \n",
    "        return img, tab_feats, label\n",
    "\n",
    "# TODO\n",
    "# PLACEHOLDER FEATURES, hangt af van koen zijn preprocessing en vooral encoding\n",
    "numeric_features = ['build_year', 'oppervlakte', 'is_monument']\n",
    "categorical_features = ['encoded_build_type', 'encoded_postcode']\n",
    "###############################################################################\n",
    "\n",
    "# Combined features list to be used in the dataset\n",
    "tabular_features = numeric_features + categorical_features\n",
    "\n",
    "# Define transforms for images\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225]), # <---- zijn pretrained vgm, gaat over RGB values\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]), # <---- zijn pretrained vgm, gaat over RGB values\n",
    "])\n",
    "\n",
    "# Initialize datasets passing all tabular features\n",
    "train_dataset = HousingDataset(train_df, tabular_features, transform=train_transforms)\n",
    "val_dataset = HousingDataset(val_df, tabular_features, transform=val_transforms)\n",
    "test_dataset = HousingDataset(test_df, tabular_features, transform=val_transforms)\n",
    "\n",
    "batch_size = 64  # Aan te passen voor GPU\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8151f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 5: Model Definition ---\n",
    "\n",
    "###### MODELLEN GAAN WE AAN SLEUTELEN, ENKEL NU VOOR DE PIPELINE ALS TEMPLATE #####\n",
    "\n",
    "class MultimodalHousingClassifier(nn.Module):\n",
    "    def __init__(self, tabular_input_dim, num_classes, cnn_output_dim=512, tabular_emb_dim=128, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN Backbone: Pretrained ResNet18 without final FC layer\n",
    "        # DIT MODEL KUNNEN WE AANPASSEN NAAR BIJV EfficientNet ETc. TODO\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) # TODO onderzoek naar pretrained weights\n",
    "        # Remove last FC layer\n",
    "        self.cnn_backbone = nn.Sequential(*list(resnet.children())[:-1])  # output: (batch, 512, 1, 1)\n",
    "        \n",
    "        # Flatten CNN output to (batch, 512)\n",
    "        self.cnn_output_dim = cnn_output_dim\n",
    "        \n",
    "        # MLP for tabular features\n",
    "        # DIT MODEL KUNNEN WE AANPASSEN NAAR BIJV TabNet ETc. TODO\n",
    "        self.tabular_mlp = nn.Sequential(\n",
    "            nn.Linear(tabular_input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, tabular_emb_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Fusion layer: concatenate CNN + tabular embeddings\n",
    "        fusion_input_dim = cnn_output_dim + tabular_emb_dim\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, tabular_data):\n",
    "        # Image forward pass through CNN backbone\n",
    "        cnn_features = self.cnn_backbone(image)  # (batch, 512, 1, 1)\n",
    "        cnn_features = cnn_features.view(-1, self.cnn_output_dim)  # flatten\n",
    "        \n",
    "        # Tabular features through MLP\n",
    "        tabular_features = self.tabular_mlp(tabular_data)\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined = torch.cat([cnn_features, tabular_features], dim=1)\n",
    "        \n",
    "        # Classification head\n",
    "        output = self.classifier(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03036414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 6: Typical Training Loop ---\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device, log_interval=10):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    loop = tqdm(dataloader, leave=True, dynamic_ncols=True)\n",
    "\n",
    "    print(\"Starting training loop...\", flush=True)\n",
    "    for batch_idx, (images, tabular_data, labels) in loop:\n",
    "        for i, (images, tabular_data, labels) in enumerate(loop):\n",
    "            print(f\"Batch {i+1}\", flush=True)\n",
    "\n",
    "        images = images.to(device)\n",
    "        tabular_data = tabular_data.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, tabular_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            current_loss = loss.item()\n",
    "            current_acc = (preds == labels.cpu().numpy()).mean()\n",
    "            print(f\"[Batch {batch_idx}/{len(dataloader)}] Loss: {current_loss:.4f} | Acc: {current_acc:.4f}\")\n",
    "\n",
    "        loop.set_description(f\"Train [{batch_idx+1}/{len(dataloader)}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    epoch_recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1, epoch_recall\n",
    "\n",
    "def validate_one_epoch(model, dataloader, criterion, device, log_interval=10):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=False)\n",
    "        for batch_idx, (images, tabular_data, labels) in loop:\n",
    "            images = images.to(device)\n",
    "            tabular_data = tabular_data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images, tabular_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                current_loss = loss.item()\n",
    "                current_acc = (preds == labels.cpu().numpy()).mean()\n",
    "                print(f\"[Val Batch {batch_idx}/{len(dataloader)}] Loss: {current_loss:.4f} | Acc: {current_acc:.4f}\")\n",
    "\n",
    "            loop.set_description(f\"Val [{batch_idx+1}/{len(dataloader)}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    epoch_recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1, epoch_recall\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10):\n",
    "    best_val_f1 = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, train_f1, train_recall = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc, val_f1, val_recall = validate_one_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\", flush=True)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, Recall: {train_recall:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Save best model based on validation F1\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"Saved best model\")\n",
    "\n",
    "    print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113dc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 7: Evaluation & Export ---\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, dataloader, device, class_names=None):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, tabular_data, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            tabular_data = tabular_data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images, tabular_data)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, path='trained_model.pth'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, path='trained_model.pth', device='cpu'):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10073b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 8: Test the Full Pipeline ---\n",
    "\n",
    "# Setup model parameters\n",
    "num_numeric = len(numeric_features)\n",
    "num_categorical = len(categorical_features)\n",
    "tabular_input_dim = num_numeric + num_categorical\n",
    "num_classes = df['woningtype'].nunique()\n",
    "\n",
    "# Initialize model and move to device\n",
    "model = MultimodalHousingClassifier(tabular_input_dim=tabular_input_dim, num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Quick test: run one epoch of training\n",
    "train_loss, train_acc, train_f1, train_recall = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "print(f\"Quick Train Epoch -> Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, Recall: {train_recall:.4f}\")\n",
    "\n",
    "# Quick test: validate\n",
    "val_loss, val_acc, val_f1, val_recall = validate_one_epoch(model, val_loader, criterion, device)\n",
    "print(f\"Quick Validation -> Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, Recall: {val_recall:.4f}\")\n",
    "\n",
    "# Evaluate model with detailed metrics and confusion matrix\n",
    "class_names = sorted(df['woningtype'].unique())\n",
    "evaluate_model(model, val_loader, device, class_names=class_names)\n",
    "\n",
    "# Save model checkpoint\n",
    "save_model(model, 'final_model.pth')\n",
    "\n",
    "# Optionally load the model and test on test set\n",
    "load_model(model, 'final_model.pth', device=device)\n",
    "evaluate_model(model, test_loader, device, class_names=class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
